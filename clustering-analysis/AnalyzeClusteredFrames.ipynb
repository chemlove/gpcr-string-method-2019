{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This file is primarily intended to be used as input to LearningClusteredFrames.ipynb**\n",
    "\n",
    "# Load trajectories and cluster indices etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T12:16:26.065033Z",
     "start_time": "2018-07-04T12:16:24.855220Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import logging\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s %(name)s-%(levelname)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "sys.path.append('MD_common/')\n",
    "import MD_fun\n",
    "import collections\n",
    "from helpfunc import *\n",
    "from colvars import *\n",
    "\n",
    "#fun = MD_fun.MD_functions()\n",
    "os.chdir(get_project_path())\n",
    "logger = logging.getLogger(\"ancf\")\n",
    "logger.info(\"Script started\")\n",
    "\n",
    "active_traj = md.load(\"{protein_db}/3p0g/3p0g.pdb\")\n",
    "logger.info(\"loaded active structure, %s\", active_traj)\n",
    "# protein database file, inactive structure with g-protein\n",
    "inactive_traj = md.load(\"{protein_db}/2rh1/2rh1.pdb\")\n",
    "logger.info(\"loaded inactive active structure, %s\", inactive_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulation and clustering metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T12:16:40.589700Z",
     "start_time": "2018-07-04T12:16:27.437178Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_absolute_indices(cluster_indices, center_indices):\n",
    "    \"\"\"Convert to absolute frame indicies\"\"\"\n",
    "    frames = np.empty(len(center_indices), dtype=int)\n",
    "    index_count = np.zeros(len(center_indices), dtype=int)\n",
    "    for traj_idx, cluster in enumerate(cluster_indices):\n",
    "        cluster_idx = cluster - 1\n",
    "        count = index_count[cluster_idx]\n",
    "        if count == center_indices[cluster_idx]:\n",
    "            frames[cluster_idx] = traj_idx\n",
    "        index_count[cluster_idx] += 1\n",
    "    return frames\n",
    "\n",
    "\n",
    "def load_cluster_representations(simulation):\n",
    "    return [simulation.traj[i] for i in simulation.cluster_rep_indices]\n",
    "    #rep_files = sorted([\n",
    "    #    f\n",
    "    #    for f in glob.glob(\n",
    "    #        simulation.clusterpath + 'clustered_frames/reps_cluster_*.dcd')\n",
    "    #])\n",
    "    #return [md.load(f, top=simulation.topology_path) for f in rep_files]\n",
    "\n",
    "\n",
    "def load_cluster_indices(simulation):\n",
    "    # Cluster files:\n",
    "    with open(simulation.clusterpath +\n",
    "              \"cluster_indices_.txt\") as cluster_indices_file:\n",
    "        simulation.cluster_indices = [int(l[0]) for l in cluster_indices_file]\n",
    "    with open(simulation.clusterpath +\n",
    "              \"center_indices.txt\") as center_indices_file:\n",
    "        # Load the center indices. The index represents where the frame occurs in the sequence of frames in that cluster\n",
    "        simulation.center_indices = [int(l[0]) for l in center_indices_file]\n",
    "    simulation.cluster_rep_indices = to_absolute_indices(\n",
    "        simulation.cluster_indices, simulation.center_indices)\n",
    "    logger.debug(\n",
    "        \"Found center indices at %s which corresponds to traj indices %s\",\n",
    "        simulation.center_indices, simulation.cluster_rep_indices)\n",
    "    simulation.cluster_representations = load_cluster_representations(simulation)\n",
    "    return simulation\n",
    "\n",
    "\n",
    "def load_default(simulation, coordinates_filetype=\"dcd\"):\n",
    "    logger.info(\"Using simulation files in directory \" + simulation.path)\n",
    "\n",
    "    simulation.topology_path = simulation.path + simulation.name + \".pdb\"\n",
    "    simulation.traj = md.load(\n",
    "        simulation.path + simulation.name + \".%s\"%coordinates_filetype,\n",
    "        top=simulation.topology_path,\n",
    "        stride=simulation.stride)\n",
    "    simulation.timestep = simulation.stride * 0.18 / 1000\n",
    "    return load_cluster_indices(simulation)\n",
    "\n",
    "\n",
    "simulation = Simulation({\n",
    "    \"condition\": \"A\",\n",
    "    \"number\": \"00\",\n",
    "    \"name\": \"all\",\n",
    "    \"stride\": 100\n",
    "})\n",
    "simulation.clusterpath=\"/home/oliverfl/projects/gpcr/mega/Result_Data/beta2-dror/clustering/\"\n",
    "simulation = load_default(simulation)\n",
    "\n",
    "times = simulation.traj.time * simulation.timestep\n",
    "logger.info(\"Done loading simulation %s\", simulation.traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an overview of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T12:16:41.313369Z",
     "start_time": "2018-07-04T12:16:40.616683Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_cluster_states(simulation):\n",
    "    plt.figure(figsize=(16, 3))\n",
    "    plt.plot(times, simulation.cluster_indices)\n",
    "    plt.ylabel(r'Clustered state')\n",
    "    plt.xlabel(\"Time $\\mu$s\")\n",
    "    plt.yticks(range(0, max(simulation.cluster_indices)))\n",
    "    plt.show()\n",
    "    plot_state_changes(times, simulation.cluster_indices)\n",
    "\n",
    "\n",
    "plot_cluster_states(simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Identify significant changes between states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T13:40:25.094848Z",
     "start_time": "2017-10-02T13:40:21.707761Z"
    }
   },
   "outputs": [],
   "source": [
    "def getAllCalphaDistances(traj, atoms):\n",
    "    res = np.empty((len(atoms), len(atoms)))\n",
    "    for i, a in enumerate(atoms):\n",
    "        res[i, i] = 0\n",
    "        for j in range(i + 1, len(atoms)):\n",
    "            dist = md.compute_distances(\n",
    "                traj, [(a.index, atoms[j].index)], periodic=False)[0]\n",
    "            res[i, j] = dist\n",
    "            res[j, i] = dist\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_distance_difference(cluster_representations, traj, atoms):\n",
    "    if len(cluster_representations) == 0:\n",
    "        return\n",
    "    number_reps = len(cluster_representations)\n",
    "    diffs = np.empty((number_reps, number_reps), dtype=object)\n",
    "    # distance_matrices = [fun.getAllCalphaDistances(t, query=query)[0] for t in cluster_representations]\n",
    "    fun = MD_fun.MD_functions()\n",
    "    distance_matrices = [\n",
    "        #fun.getAllCalphaDistances(t)[0] for t in cluster_representations\n",
    "        getAllCalphaDistances(t, atoms) for t in cluster_representations\n",
    "    ]\n",
    "    # print(distance_matrices)\n",
    "    zero_array = np.zeros(distance_matrices[0].shape)\n",
    "    for i, dist1 in enumerate(distance_matrices):\n",
    "        diffs[i, i] = zero_array\n",
    "        for j in range(i + 1, number_reps):\n",
    "            diff = dist1 - distance_matrices[j]\n",
    "            diffs[i, j] = diff\n",
    "            diffs[j, i] = diff\n",
    "    return diffs, distance_matrices\n",
    "\n",
    "\n",
    "def compute_transition_matrix(cluster_indices):\n",
    "    counter = collections.Counter(cluster_indices)\n",
    "    matrix = np.zeros((len(counter), len(counter)))\n",
    "    for i, cluster in enumerate(cluster_indices):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        last_cluster = cluster_indices[i - 1]\n",
    "        # remember to offset indices by -1\n",
    "        matrix[last_cluster - 1, cluster - 1] += 1\n",
    "    # normalize and return\n",
    "    transition_count = len(cluster_indices) - 1\n",
    "    return matrix / transition_count\n",
    "\n",
    "def save_clusterrep_pdb(simulation):\n",
    "    pdb_name = '(%s_stride_%s)' % (simulation.id, simulation.stride)\n",
    "    for idx, rep in enumerate(simulation.cluster_representations):\n",
    "        filename = '%s/clustered_frames/%s_stride_%s_reps_cluster_%s.pdb' % (\n",
    "            simulation.clusterpath, simulation.id, simulation.stride, idx + 1)\n",
    "        rep.save(filename)  \n",
    "\n",
    "save_clusterrep_pdb(simulation)\n",
    "\n",
    "protein_CA_q = \"protein and name CA and chainid 0\"\n",
    "atoms = get_atoms(protein_CA_q, simulation.traj.topology, sort=False)\n",
    "\n",
    "# inactive_atoms = get_atoms(protein_CA_q, inactive_traj.topology, sort=False)\n",
    "# inactive_differences = getAllCalphaDistances(inactive_traj, inactive_atoms)\n",
    "# active_atoms = get_atoms(protein_CA_q, active_traj.topology, sort=False)\n",
    "# active_differences = getAllCalphaDistances(active_traj, active_atoms)\n",
    "\n",
    "distance_differences, distance_matrices = compute_distance_difference(\n",
    "    simulation.cluster_representations, simulation.traj, atoms)\n",
    "transition_matrix = compute_transition_matrix(simulation.cluster_indices)\n",
    "\n",
    "logger.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most significant features of clusters\n",
    "- By comparing distance differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T13:40:26.696821Z",
     "start_time": "2017-10-02T13:40:25.096762Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AtomPair(object):\n",
    "    def getDist(self):\n",
    "        return self.dist\n",
    "\n",
    "    def getScaledDist(self):\n",
    "        return self.scaled_dist\n",
    "\n",
    "    def getNormDist(self):\n",
    "        return self.norm_dist\n",
    "\n",
    "    def __init__(self, dist, atom1, atom2, params={}):\n",
    "        self.__dict__.update(params)\n",
    "        self.__dict__.update({\"dist\": dist, \"atom1\": atom1, \"atom2\": atom2})\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, params={}):\n",
    "        self.__dict__.update(params)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "    def getColor(self):\n",
    "        return self.color\n",
    "\n",
    "\n",
    "class Graph(object):\n",
    "    def __init__(self, params={}):\n",
    "        self.__dict__.update(params)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "    def vmd_bonds_script(self):\n",
    "        bonds_script = \"\"\n",
    "        for n1 in self.nodes:\n",
    "            for n2 in n1.neighbours:\n",
    "                if n2.color > n1.color:\n",
    "                    bonds_script += vmd_bond(n1.atom, n2.atom)\n",
    "        return \"for {set x 0} {$x <= 5} {incr x} {%s}\" % (bonds_script)\n",
    "\n",
    "    def plot_distances(graph,\n",
    "                       simulation,\n",
    "                       max_per_plot=10,\n",
    "                       histogram=False,\n",
    "                       bincount=10,\n",
    "                       separate_clusters=False,\n",
    "                       use_contacts=False):\n",
    "        traj = simulation.traj\n",
    "        pairs = []\n",
    "        labels = []\n",
    "\n",
    "        def _plot_once(dist, label):\n",
    "            if histogram:\n",
    "                plt.hist(dist[~np.isnan(dist)], bincount, alpha=(0.3 if separate_clusters else 0.5), label=label)\n",
    "            else:\n",
    "                plt.plot(dist, '--', alpha=0.5, label=label)\n",
    "\n",
    "        def plot():\n",
    "            dists = md.compute_distances(traj, np.array(pairs), periodic=False)\n",
    "            if use_contacts:\n",
    "                dists = 1/dists\n",
    "            for i in range(0, dists.shape[1]):\n",
    "                dist = dists[:, i]\n",
    "                label = labels[i]\n",
    "                if separate_clusters:\n",
    "                    for cl in range(0, len(simulation.cluster_rep_indices)):\n",
    "                        cluster = cl + 1 \n",
    "                        values = np.empty(len(dist))\n",
    "                        for idx in range(0, len(dist)):\n",
    "                            values[idx] = dist[idx] if simulation.cluster_indices[\n",
    "                                idx] == cluster else np.nan\n",
    "                        _plot_once(values, label + \"(cluster \" + str(cl+1) + \")\")\n",
    "                else:\n",
    "                    _plot_once(dist, label)\n",
    "            distlabel= \"Contact (1/nm)\" if use_contacts else \"Dists (nm)\"\n",
    "            if histogram:\n",
    "                plt.xlabel(distlabel)\n",
    "                plt.ylabel(\"Count\")\n",
    "            else:\n",
    "                plt.xlabel(\"Frame#\")\n",
    "                plt.ylabel(distlabel)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        for n1 in graph.nodes:\n",
    "            for n2 in n1.neighbours:\n",
    "                if n2.color > n1.color:\n",
    "                    pairs.append([n1.atom.index, n2.atom.index])\n",
    "                    labels.append(\"%s-%s\" % (n1.atom, n2.atom))\n",
    "                    if len(pairs) % max_per_plot == 0:\n",
    "                        plot()\n",
    "                        pairs = []\n",
    "                        labels = []\n",
    "        if len(pairs) > 0:\n",
    "            plot()\n",
    "\n",
    "\n",
    "    def number_bonds(self):\n",
    "        count = 0\n",
    "        for n1 in self.nodes:\n",
    "            for n2 in n1.neighbours:\n",
    "                if n2.color > n1.color:\n",
    "                    count += 1\n",
    "        return count\n",
    "\n",
    "    def find_subgraphs(graph):\n",
    "        def traverse(nodes, visited):\n",
    "            for n1 in nodes:\n",
    "                key1 = str(n1.atom)\n",
    "                if visited.get(key1) is not None:\n",
    "                    continue\n",
    "                visited[key1] = n1\n",
    "                traverse(n1.neighbours, visited)\n",
    "\n",
    "        all_visited = {}\n",
    "        subgraph_idx = 0\n",
    "        subgraphs = []\n",
    "        for n in graph.nodes:\n",
    "            key = str(n.atom)\n",
    "            if all_visited.get(key) is not None:\n",
    "                continue\n",
    "            all_visited[key] = n\n",
    "            visited = {key: n}\n",
    "            traverse(n.neighbours, visited)\n",
    "            for k, node in visited.items():\n",
    "                node.subgraph = subgraph_idx\n",
    "                all_visited[k] = node\n",
    "            subgraph_idx += 1\n",
    "            subgraphs.append([visited[k] for k in sorted(visited.keys())])\n",
    "            #logger.debug(\"Visited nodes for subgraph: %s\", visited)\n",
    "        graph.subgraphs = subgraphs\n",
    "\n",
    "    def color(graph, split_subgraphs=False):\n",
    "        \"\"\"\n",
    "        Simple algorithm to put colors on nodes in a graph so that no neighbours have the same color, \n",
    "        i.e. creating a multipartite graph. \n",
    "        # based on https://gist.github.com/sramana/583681\n",
    "\n",
    "        if split_subgraphs is True, then the graph will be split into disconnected subgraphs. \n",
    "        All subgraphs will then be partitioned with different colors\n",
    "        \"\"\"\n",
    "        blocked_colors = {}\n",
    "\n",
    "        def promising(node, color):\n",
    "            for neighbor in node.neighbours:\n",
    "                if neighbor.color == color:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        def get_color_for_node(node):\n",
    "            for color in graph.colors:\n",
    "                if blocked_colors.get(color, False):\n",
    "                    continue\n",
    "                if promising(node, color):\n",
    "                    return color\n",
    "            return None\n",
    "\n",
    "        if split_subgraphs:\n",
    "            graph.find_subgraphs()\n",
    "            all_nodes = graph.subgraphs\n",
    "        else:\n",
    "            all_nodes = [graph.nodes]\n",
    "        for nodes in all_nodes:\n",
    "            used_colors = []\n",
    "            for n in nodes:\n",
    "                color = get_color_for_node(n)\n",
    "                if color is None:\n",
    "                    return False\n",
    "                n.color = color\n",
    "                used_colors.append(color)\n",
    "            if split_subgraphs:\n",
    "                for color in used_colors:\n",
    "                    blocked_colors[color] = True\n",
    "        return True\n",
    "\n",
    "    def explain_to_human(graph):\n",
    "        color_to_nodes = {}\n",
    "        text = \"\\nThere were %s atoms, %s bonds and %s colors in the graph (%s subgraphs)\\n\" % (\n",
    "            len(graph.nodes), graph.number_bonds(), len(graph.colors),\n",
    "            len(graph.subgraphs) if hasattr(graph, 'subgraphs') else 1)\n",
    "\n",
    "        def to_colors(node):\n",
    "            return sorted(set([n.color for n in node.neighbours]))\n",
    "\n",
    "        for node in graph.nodes:\n",
    "            nodes = color_to_nodes.get(node.color, [])\n",
    "            nodes.append(node)\n",
    "            color_to_nodes[node.color] = nodes\n",
    "        for color, nodes in color_to_nodes.items():\n",
    "            #         logger.info(\n",
    "            #             \"VMD query for color %s:\\n%s\",\n",
    "            #             color,\n",
    "            #             to_vmd_query([n.atom for n in nodes],atom_name=\"CA\"))\n",
    "            text += \"\\n - There were \" + \\\n",
    "                str(len(nodes)) + \" with color \" + str(color) + \". Out of these \"\n",
    "            color_to_connections = {}\n",
    "            for node in nodes:\n",
    "                connected_colors = to_colors(node)\n",
    "                key = str(connected_colors)\n",
    "                value = color_to_connections.get(key, (connected_colors, []))\n",
    "                value[1].append(node)\n",
    "                color_to_connections[key] = value\n",
    "            first = False\n",
    "            for colors, nodes in color_to_connections.values():\n",
    "                text += (\" and\" if first else \"\") + str(len(nodes)) + \\\n",
    "                    \" atoms were displaced from atoms with color \" + str(colors)\n",
    "                first = False\n",
    "        logger.info(\"Explanation for graph: %s:\", text)\n",
    "        logger.info(\"VMD query for atoms in graph:\\n%s\",\n",
    "                    graph.vmd_atom_selection())\n",
    "        logger.info(\"VMD atom coloring script:\\n%s\",\n",
    "                    graph.vmd_atom_colors_script())\n",
    "        logger.info(\"VMD query for bonds in graph:\\n%s\",\n",
    "                    graph.vmd_bonds_script())\n",
    "\n",
    "    def vmd_atom_selection(self, color=None):\n",
    "        return to_vmd_query(\n",
    "            [n.atom for n in self.nodes if color is None or n.color == color],\n",
    "            atom_name=\"CA\")\n",
    "\n",
    "    def vmd_atom_colors_script(self):\n",
    "        text = \"\"\n",
    "        for color in self.colors:\n",
    "            text += \"set color%s [atomselect top \\\"%s\\\"];\" % (\n",
    "                color, self.vmd_atom_selection(color=color))\n",
    "            text += \"$color%s set beta %s;\" % (color, color)\n",
    "        return text\n",
    "\n",
    "\n",
    "def partition_as_graph(atompairs,\n",
    "                       dist_func=AtomPair.getDist,\n",
    "                       cutoff=1.0,\n",
    "                       max_partition_count=10,\n",
    "                       split_subgraphs=False):\n",
    "    # extract atoms and build a graph\n",
    "    # TODO a log(n2) midpoint method to find the optimal color count is better\n",
    "    for color_count in range(1, max_partition_count + 1):\n",
    "        graph = Graph({\"nodes\": [], \"colors\": range(0, color_count), \"atompairs\" : []})\n",
    "        name_to_nodes = {}\n",
    "\n",
    "        def get_node(a):\n",
    "            name = str(a)\n",
    "            node = name_to_nodes.get(name)\n",
    "            if node is None:\n",
    "                node = Node({\n",
    "                    \"atom\": a,\n",
    "                    \"neighbours\": [],\n",
    "                    \"dists\": [],\n",
    "                    \"color\": None\n",
    "                })\n",
    "                name_to_nodes[name] = node\n",
    "            return node\n",
    "\n",
    "        for ap in atompairs:\n",
    "            dist = dist_func(ap)\n",
    "            if dist < cutoff:\n",
    "                continue\n",
    "            node1 = get_node(ap.atom1)\n",
    "            node2 = get_node(ap.atom2)\n",
    "            node1.neighbours.append(node2)\n",
    "            node1.dists.append(dist)\n",
    "            node2.neighbours.append(node1)\n",
    "            node2.dists.append(dist)\n",
    "            graph.atompairs.append(ap)\n",
    "        graph.nodes = [name_to_nodes[n] for n in sorted(name_to_nodes.keys())]\n",
    "        if graph.color(split_subgraphs=split_subgraphs):\n",
    "            # we managed to color the graph. stop here\n",
    "            return graph\n",
    "    raise Exception(\"Could not split/color graph into \" +\n",
    "                    str(max_partition_count) + \" partitions\")\n",
    "\n",
    "\n",
    "def get_reference_dist(atom1, atom2, ref_traj):\n",
    "    ref_atom1 = find_atom(\n",
    "        atom1.element.symbol,\n",
    "        str(atom1.residue),\n",
    "        atom1.name,\n",
    "        ref_traj,\n",
    "        query=protein_CA_q)\n",
    "    ref_atom2 = find_atom(\n",
    "        atom2.element.symbol,\n",
    "        str(atom2.residue),\n",
    "        atom2.name,\n",
    "        ref_traj,\n",
    "        query=protein_CA_q)\n",
    "    if ref_atom1 is None or ref_atom2 is None:\n",
    "        return None\n",
    "    return abs(\n",
    "        md.compute_distances(\n",
    "            ref_traj, [(ref_atom1.index, ref_atom2.index)], periodic=False)[0])\n",
    "\n",
    "\n",
    "def map_value_indices(matrix,\n",
    "                      atoms,\n",
    "                      reference_dists,\n",
    "                      symmetric=False,\n",
    "                      sort=True,\n",
    "                      sigma=1):\n",
    "    \"\"\"Find the max elements of the (2D) matrix and return a tuple with the value and the indices, sorted according to their value\"\"\"\n",
    "    dim = matrix.shape\n",
    "    res = []\n",
    "    for i in range(0, dim[0]):\n",
    "        for j in range(i + 1 if symmetric else 0, dim[1]):\n",
    "            dist = abs((matrix[i, j]))\n",
    "            pair = AtomPair(dist, atoms[i], atoms[j])\n",
    "            ref_dists = reference_dists[i, j]**sigma  # NOTE EXPONENT\n",
    "            pair.scaled_dist = np.nan if ref_dists == 0 else dist / ref_dists\n",
    "            res.append(pair)\n",
    "    # print(res)\n",
    "    # return np.array(res, dtype=object)\n",
    "    return res\n",
    "\n",
    "\n",
    "def to_atom_pairs(simulation,\n",
    "                  atoms,\n",
    "                  distance_differences,\n",
    "                  distance_matrices,\n",
    "                  transition_matrix,\n",
    "                  transition_cutoff=0.00001):\n",
    "    # print(transition_matrix)\n",
    "    # print(atoms)\n",
    "    # Create reference distances which equal the average distance between atoms in all frames\n",
    "    reference_dists = np.zeros(distance_matrices[0].shape)\n",
    "    for i in range(0, len(distance_matrices)):\n",
    "        reference_dists += distance_matrices[i]\n",
    "    reference_dists = reference_dists / len(distance_matrices)\n",
    "    number_to_print = 0\n",
    "    all_pairs = None  # sum distance differences\n",
    "    for i in range(0, distance_differences.shape[0]):\n",
    "        for j in range(i + 1, distance_differences.shape[1]):\n",
    "            # Skip transition which did not occur\n",
    "            if transition_matrix[i,\n",
    "                                 j] < transition_cutoff and transition_matrix[j,\n",
    "                                                                              i] < transition_cutoff:\n",
    "                logger.info(\n",
    "                    \"No direct path between clusters %s and %s. Skipping analysis\",\n",
    "                    i + 1, j + 1)\n",
    "                continue\n",
    "            value_indices = map_value_indices(\n",
    "                distance_differences[i, j],\n",
    "                atoms,\n",
    "                reference_dists,\n",
    "                symmetric=True)\n",
    "            max_diff = max(value_indices, key=AtomPair.getDist).dist\n",
    "            for rank, pair in enumerate(\n",
    "                    sorted(value_indices, key=AtomPair.getDist, reverse=True)):\n",
    "                if rank < number_to_print:\n",
    "                    logger.debug(\"max distance between clusters %s and %s: %s\",\n",
    "                                 i + 1, j + 1, pair)\n",
    "                pair.rank = rank + 1  # avoid zero rank which leads to division by zero\n",
    "                pair.norm_dist = pair.dist / max_diff\n",
    "            if all_pairs is None:\n",
    "                all_pairs = value_indices\n",
    "            else:\n",
    "                for idx, total_pair in enumerate(all_pairs):\n",
    "                    pair = value_indices[idx]\n",
    "                    total_pair.dist += pair.dist\n",
    "                    total_pair.rank += pair.rank\n",
    "                    total_pair.norm_dist += pair.norm_dist\n",
    "        return all_pairs\n",
    "\n",
    "\n",
    "def analyze_pair_distances(simulation,\n",
    "                           atoms,\n",
    "                           distance_differences,\n",
    "                           distance_matrices,\n",
    "                           transition_matrix,\n",
    "                           percentile=99.9,\n",
    "                           dist_func=AtomPair.getNormDist,\n",
    "                           plot_dist_distribution=True,\n",
    "                           split_subgraphs=False):\n",
    "    all_pairs = to_atom_pairs(simulation, atoms, distance_differences,\n",
    "                              distance_matrices, transition_matrix)\n",
    "    number_to_print = 0\n",
    "    # low rank is better\n",
    "    logger.info(\"#####Top %s totally most displaced atoms between clusters:\",\n",
    "                number_to_print)\n",
    "    for pair in sorted(\n",
    "            all_pairs, key=AtomPair.getDist, reverse=True)[0:number_to_print]:\n",
    "        logger.debug(\"max distance: %s\", pair)\n",
    "    logger.info(\n",
    "        \"#####Top %s totally most displaced (scaled) atoms between clusters:\",\n",
    "        number_to_print)\n",
    "    scaled_sorted = sorted(all_pairs, key=AtomPair.getScaledDist, reverse=True)\n",
    "    for pair in scaled_sorted[0:number_to_print]:\n",
    "        logger.debug(\"max distance: %s\", pair)\n",
    "\n",
    "#     logger.info(\n",
    "#         \"#####Top %s ranked displaced atoms between clusters:\", number_to_print)\n",
    "#     for pair in sorted(all_pairs, key=lambda ap: ap.rank)[0:number_to_print]:\n",
    "#         logger.debug(\n",
    "#             \"max rank: %s\", pair)\n",
    "\n",
    "    logger.info(\"#####Top %s norm displaced atoms between clusters:\",\n",
    "                number_to_print)\n",
    "    #rank_scale = math.sqrt(len(simulation.cluster_representations))\n",
    "    norm_sorted = sorted(all_pairs, key=AtomPair.getNormDist, reverse=True)\n",
    "    for pair in norm_sorted[0:number_to_print]:\n",
    "        logger.debug(\"max distance: %s\", pair)\n",
    "\n",
    "    # Create a multipartite graph\n",
    "    final_distances = np.array([dist_func(p) for p in all_pairs])\n",
    "    cutoff = np.percentile(final_distances, percentile)\n",
    "    logger.info(\"#####Computing scaled differences with cutoff %s\", cutoff)\n",
    "    graph = partition_as_graph(\n",
    "        all_pairs,\n",
    "        dist_func=dist_func,\n",
    "        cutoff=cutoff,\n",
    "        split_subgraphs=split_subgraphs)\n",
    "    if plot_dist_distribution:\n",
    "        plt.hist(final_distances, 50, label=\"Count\")\n",
    "        plt.xlabel(\"Distance\")\n",
    "        plt.plot(\n",
    "            cutoff,\n",
    "            30,\n",
    "            '*',\n",
    "            label=\"Cutoff for %s percentile at %s\" % (percentile, cutoff))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    # for node in color_to_nodes.get(color):\n",
    "    # print(node.atom)\n",
    "    save_csv(\"rank_cluster_indices\", [(p.rank, p.dist,\n",
    "                                       p.scaled_dist, p.atom1, p.atom2)\n",
    "                                      for p in all_pairs], simulation)\n",
    "    return all_pairs, graph\n",
    "\n",
    "percentile = 99.9\n",
    "all_pairs, graph = analyze_pair_distances(\n",
    "    simulation,\n",
    "    atoms,\n",
    "    distance_differences,\n",
    "    distance_matrices,\n",
    "    transition_matrix,\n",
    "    percentile=percentile,\n",
    "    split_subgraphs=True)\n",
    "graph.explain_to_human()\n",
    "# print(distance_diff_matrix)\n",
    "logger.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T13:32:06.010264Z",
     "start_time": "2017-07-19T13:32:05.923828Z"
    }
   },
   "source": [
    "# Try and visualize cluster and CVs\n",
    "## Create CV object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T13:40:26.745072Z",
     "start_time": "2017-10-02T13:40:26.698277Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_cluster_rep_rmsd_cvs(cluster_representations):\n",
    "    q_CA = \"protein and chainid 0 and name CA\"\n",
    "    return [\n",
    "        RmsdCV(\"rmsd_cluster_rep_%s\" % i, rep, q_CA)\n",
    "        for i, rep in enumerate(cluster_representations)\n",
    "    ]\n",
    "\n",
    "\n",
    "def compute_color_mean_distance(simu_traj, graph, color1, color2):\n",
    "    dists = None\n",
    "    for n1 in graph.nodes:\n",
    "        if n1.color == color1:\n",
    "            for n2 in graph.nodes:\n",
    "                if n2.color == color2 and n2 in n1.neighbours:\n",
    "                    d = compute_distance_CA_atoms(n1.atom.residue,\n",
    "                                                  n2.atom.residue, simu_traj)\n",
    "                    if dists is None:\n",
    "                        dists = d\n",
    "                    else:\n",
    "                        dists = np.concatenate((dists, d), axis=1)\n",
    "    return np.mean(dists, axis=1)\n",
    "\n",
    "\n",
    "def most_relevant_dist_generator(graph, pairs, id_prefix=\"\", compute_contact=False):\n",
    "    \"\"\"\n",
    "    Returns a generator which just picks to greatest distance between color and uses that a representative\n",
    "    \"\"\"\n",
    "    color_most_relevant = {}\n",
    "    for n1 in graph.nodes:\n",
    "        for idx, n2 in enumerate(n1.neighbours):\n",
    "            if n2.color <= n1.color:\n",
    "                continue\n",
    "            color_id = str(n1.color) + \"-\" + str(n2.color)\n",
    "            d = n1.dists[idx]\n",
    "            current = color_most_relevant.get(color_id)\n",
    "            if current is None or current[0] < d:\n",
    "                color_most_relevant[color_id] = (d, n1.atom, n2.atom)\n",
    "    vmd_query = \"\"\n",
    "    for (d, atom1, atom2) in color_most_relevant.values():\n",
    "        vmd_query += vmd_bond(atom1, atom2)\n",
    "    logger.debug(\"Most relevant atoms for color pairs: %s. \\nBond query:\\n%s\",\n",
    "                 color_most_relevant, vmd_query)\n",
    "\n",
    "    def cv_generator(simu_traj, graph, color1, color2):\n",
    "        color_id = \"%s-%s\" % (color1, color2)\n",
    "        dist, atom1, atom2 = color_most_relevant.get(color_id)\n",
    "        atom_dist= compute_distance_CA_atoms(atom1.residue, atom2.residue,\n",
    "                                         simu_traj)\n",
    "        return 1/atom_dist if compute_contact else atom_dist\n",
    "\n",
    "    def id_generator(graph, color1, color2):\n",
    "        color_id = \"%s-%s\" % (color1, color2)\n",
    "        dist, atom1, atom2 = color_most_relevant.get(color_id)\n",
    "        id_template = \"%s1/|%s-%s|\" if compute_contact else \"%s|%s-%s|\"\n",
    "        return id_template % (id_prefix, atom1, atom2)\n",
    "\n",
    "    return cv_generator, id_generator\n",
    "\n",
    "\n",
    "def colors_connected(graph, color1, color2):\n",
    "    for n1 in graph.nodes:\n",
    "        if n1.color == color1:\n",
    "            for n2 in n1.neighbours:\n",
    "                if n2.color == color2:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def create_cvs(\n",
    "        graph,\n",
    "        CV_generator=compute_color_mean_distance,\n",
    "        ID_generator=lambda graph, color1, color2: \"color|%s-%s|\" % (color1, color2)\n",
    "):\n",
    "    color_combos = [c for c in itertools.combinations(graph.colors, 2)]\n",
    "    cvs = []\n",
    "    for color1, color2 in color_combos:\n",
    "        if colors_connected(graph, color1, color2):\n",
    "            id = ID_generator(graph, color1, color2)\n",
    "            cv = ColorCv(graph, id, color1, color2, CV_generator)\n",
    "            cvs.append(cv)\n",
    "    return cvs\n",
    "\n",
    "\n",
    "cvs = create_cvs(graph, CV_generator=compute_color_mean_distance)\n",
    "# cvs = create_cvs(graph, CV_generator=compute_color_center_distance)\n",
    "#cvs = create_cvs(graph, CV_generator=most_relevant_dist_generator(graph, all_pairs))\n",
    "\n",
    "rep_rmsd_cvs = create_cluster_rep_rmsd_cvs(simulation.cluster_representations)\n",
    "logger.info(\n",
    "    \"Done. Created %s collective variables of colors and %s of rmsd to center indices\",\n",
    "    len(cvs), len(rep_rmsd_cvs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-19T15:00:03.606179Z",
     "start_time": "2017-07-19T15:00:03.591354Z"
    }
   },
   "source": [
    "## Cluster plot using graph colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T13:40:27.683618Z",
     "start_time": "2017-10-02T13:40:26.748151Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_color_center_distance(simu_traj, graph, color1, color2):\n",
    "    #Get center of mass vector for each color\n",
    "    color1_atoms = [n.atom.index for n in graph.nodes if n.color == color1]\n",
    "    color2_atoms = [n.atom.index for n in graph.nodes if n.color == color2]\n",
    "    center1 = md.compute_center_of_mass(simu_traj.atom_slice(color1_atoms))\n",
    "    center2 = md.compute_center_of_mass(simu_traj.atom_slice(color2_atoms))\n",
    "    #TODO periodic distance\n",
    "    return np.linalg.norm(center1 - center2, axis=1)\n",
    "\n",
    "\n",
    "def create_cluster_plots(simulation, pairs, graph, cvs):\n",
    "    logger.info(\"Creating cluster plots for %s colors\", len(graph.colors))\n",
    "    for i, cvx in enumerate(cvs):\n",
    "        for j in range(i + 1, len(cvs)):\n",
    "            cvy = cvs[j]\n",
    "            cluster_scatterplot(\n",
    "                simulation,\n",
    "                cvx.eval(simulation.traj),\n",
    "                cvy.eval(simulation.traj),\n",
    "                xlabel=cvx.id,\n",
    "                ylabel=cvy.id,\n",
    "                title=\"Simulation \" + simulation.condition + \"-\" +\n",
    "                simulation.number,\n",
    "                alpha=0.15)\n",
    "\n",
    "create_cluster_plots(simulation, all_pairs, graph, cvs)\n",
    "logger.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 1 A from Dror paper\n",
    "expecting to see 3 clusters in active, intermediate and inactive states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T12:16:42.136362Z",
     "start_time": "2018-07-04T12:16:41.336264Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_helix6helix3dist_npxxy_rmsd(simulation, active_traj, inactive_traj):\n",
    "    q = \"chainid 0 and protein and (residue 322 to 327) and name CA\" \n",
    "    active_rmsds, inactive_rmsds = compute_active_inactive_rmsd(simulation.traj, active_traj, inactive_traj, q)\n",
    "    helix_63_dist = compute_distance_CA_atoms(\n",
    "        'ARG131', 'LEU272', simulation.traj)\n",
    "    plt.plot(helix_63_dist, inactive_rmsds)\n",
    "    plt.xlabel(r'Helix 6-helix 3 distance')\n",
    "    plt.ylabel(r'NPxxY region rmsd to inactive')  \n",
    "    plt.title(\"Time parametrized path between states\")\n",
    "    plt.show()\n",
    "    cluster_scatterplot(simulation, helix_63_dist, inactive_rmsds,\n",
    "                        xlabel=r'Helix 6-helix 3 distance (nm)',\n",
    "                        ylabel=r'NPxxY region rmsd to inactive (nm)',\n",
    "                        title=\"As in paper, Simulation \" + simulation.condition + \"-\" + simulation.number,\n",
    "                        alpha=0.3)\n",
    "\n",
    "plot_helix6helix3dist_npxxy_rmsd(simulation, active_traj, inactive_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Against inactive/active ref structure RMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T13:40:28.631103Z",
     "start_time": "2017-10-02T13:40:28.185682Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_active_inactive_rmsds(simulation, active_traj, inactive_traj):\n",
    "    q = \"chainid 0 and protein and name CA\"\n",
    "    active_rmsds, inactive_rmsds = compute_active_inactive_rmsd(\n",
    "        simulation.traj, active_traj, inactive_traj, q)\n",
    "    #plt.plot(active_rmsds,inactive_rmsds)\n",
    "    cluster_scatterplot(\n",
    "        simulation,\n",
    "        active_rmsds,\n",
    "        inactive_rmsds,\n",
    "        xlabel=r'rmsd to active',\n",
    "        ylabel=r'rmsd to inactive',\n",
    "        title=\"Simulation \" + simulation.condition + \"-\" + simulation.number,\n",
    "        alpha=0.25)\n",
    "\n",
    "plot_active_inactive_rmsds(simulation, active_traj, inactive_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T13:33:06.702312Z",
     "start_time": "2017-09-06T13:33:06.697058Z"
    }
   },
   "source": [
    "## RMSDs to cluster reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-02T13:40:29.915016Z",
     "start_time": "2017-10-02T13:40:28.632447Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cluster_reps_rmsds(simulation, rep_rmsd_cvs):\n",
    "    for i, cvi in enumerate(rep_rmsd_cvs):\n",
    "        rmsdsi = cvi.eval(simulation.traj)\n",
    "        for j in range(i + 1, len(rep_rmsd_cvs)):\n",
    "            cvj = rep_rmsd_cvs[j]\n",
    "            rmsdsj = cvj.eval(simulation.traj)\n",
    "            cluster_scatterplot(\n",
    "                simulation,\n",
    "                rmsdsi,\n",
    "                rmsdsj,\n",
    "                xlabel=r'rmsd to cluster rep %s' % (i + 1),\n",
    "                ylabel=r'rmsd to cluster rep %s' % (j + 1),\n",
    "                title=\"Simulation \" + simulation.condition + \"-\" +\n",
    "                simulation.number,\n",
    "                alpha=0.07)\n",
    "\n",
    "\n",
    "plot_cluster_reps_rmsds(simulation, rep_rmsd_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "792px",
    "left": "9px",
    "right": "20px",
    "top": "104px",
    "width": "245px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 678,
   "position": {
    "height": "324px",
    "left": "16px",
    "right": "20px",
    "top": "147px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
